{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import collections\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>trending_days</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9wRQljFNDW8</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...</td>\n",
       "      <td>NFL</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T02:05:26.000Z</td>\n",
       "      <td>NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...</td>\n",
       "      <td>81377</td>\n",
       "      <td>655</td>\n",
       "      <td>25</td>\n",
       "      <td>177</td>\n",
       "      <td>https://i.ytimg.com/vi/9wRQljFNDW8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>New England Patriots returner Dion Lewis blast...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Om_zGhJLZ5U</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>TL;DW - Every DCEU Movie Before Justice League</td>\n",
       "      <td>Screen Junkies</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-12T18:00:03.000Z</td>\n",
       "      <td>screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...</td>\n",
       "      <td>288922</td>\n",
       "      <td>7515</td>\n",
       "      <td>792</td>\n",
       "      <td>2111</td>\n",
       "      <td>https://i.ytimg.com/vi/Om_zGhJLZ5U/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>With Justice League approaching fast we rewatc...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>goP4Z5wyOlM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Iraq-Iran earthquake: Deadly tremor hits borde...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-12T21:16:40.000Z</td>\n",
       "      <td>bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...</td>\n",
       "      <td>34785</td>\n",
       "      <td>308</td>\n",
       "      <td>26</td>\n",
       "      <td>413</td>\n",
       "      <td>https://i.ytimg.com/vi/goP4Z5wyOlM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A strong 7.2-magnitude earthquake has rattled ...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>STI2fI7sKMo</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>AFFAIRS, EX BOYFRIENDS, $18MILLION NET WORTH -...</td>\n",
       "      <td>Shawn Johnson East</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-11T15:00:03.000Z</td>\n",
       "      <td>shawn johnson|\"andrew east\"|\"shawn east\"|\"shaw...</td>\n",
       "      <td>321053</td>\n",
       "      <td>4451</td>\n",
       "      <td>1772</td>\n",
       "      <td>895</td>\n",
       "      <td>https://i.ytimg.com/vi/STI2fI7sKMo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Subscribe for weekly videos ▶ http://bit.ly/sj...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>ogYum4kWXgk</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>People are Awesome &amp; The Pet Collective presen...</td>\n",
       "      <td>People are Awesome</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T13:00:06.000Z</td>\n",
       "      <td>people are awesome|\"people are awesome 2017\"|\"...</td>\n",
       "      <td>69844</td>\n",
       "      <td>3417</td>\n",
       "      <td>33</td>\n",
       "      <td>160</td>\n",
       "      <td>https://i.ytimg.com/vi/ogYum4kWXgk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Pets are Awesome! This is for all the animal l...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id trending_date  \\\n",
       "10  9wRQljFNDW8      17.14.11   \n",
       "36  Om_zGhJLZ5U      17.14.11   \n",
       "41  goP4Z5wyOlM      17.14.11   \n",
       "44  STI2fI7sKMo      17.14.11   \n",
       "46  ogYum4kWXgk      17.14.11   \n",
       "\n",
       "                                                title       channel_title  \\\n",
       "10  Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...                 NFL   \n",
       "36     TL;DW - Every DCEU Movie Before Justice League      Screen Junkies   \n",
       "41  Iraq-Iran earthquake: Deadly tremor hits borde...            BBC News   \n",
       "44  AFFAIRS, EX BOYFRIENDS, $18MILLION NET WORTH -...  Shawn Johnson East   \n",
       "46  People are Awesome & The Pet Collective presen...  People are Awesome   \n",
       "\n",
       "    category_id              publish_time  \\\n",
       "10           17  2017-11-13T02:05:26.000Z   \n",
       "36            1  2017-11-12T18:00:03.000Z   \n",
       "41           25  2017-11-12T21:16:40.000Z   \n",
       "44           22  2017-11-11T15:00:03.000Z   \n",
       "46           24  2017-11-13T13:00:06.000Z   \n",
       "\n",
       "                                                 tags   views  likes  \\\n",
       "10  NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...   81377    655   \n",
       "36  screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...  288922   7515   \n",
       "41  bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...   34785    308   \n",
       "44  shawn johnson|\"andrew east\"|\"shawn east\"|\"shaw...  321053   4451   \n",
       "46  people are awesome|\"people are awesome 2017\"|\"...   69844   3417   \n",
       "\n",
       "    dislikes  comment_count                                  thumbnail_link  \\\n",
       "10        25            177  https://i.ytimg.com/vi/9wRQljFNDW8/default.jpg   \n",
       "36       792           2111  https://i.ytimg.com/vi/Om_zGhJLZ5U/default.jpg   \n",
       "41        26            413  https://i.ytimg.com/vi/goP4Z5wyOlM/default.jpg   \n",
       "44      1772            895  https://i.ytimg.com/vi/STI2fI7sKMo/default.jpg   \n",
       "46        33            160  https://i.ytimg.com/vi/ogYum4kWXgk/default.jpg   \n",
       "\n",
       "    comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "10              False             False                   False   \n",
       "36              False             False                   False   \n",
       "41              False             False                   False   \n",
       "44              False             False                   False   \n",
       "46              False             False                   False   \n",
       "\n",
       "                                          description  trending_days region  \n",
       "10  New England Patriots returner Dion Lewis blast...              1     US  \n",
       "36  With Justice League approaching fast we rewatc...              1     US  \n",
       "41  A strong 7.2-magnitude earthquake has rattled ...              1     US  \n",
       "44  Subscribe for weekly videos ▶ http://bit.ly/sj...              1     US  \n",
       "46  Pets are Awesome! This is for all the animal l...              1     US  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nations = ['US', 'IN', 'DE', 'GB', 'JP']\n",
    "country = pd.DataFrame()\n",
    "for nation in nations:\n",
    "    df = pd.DataFrame()\n",
    "    filename = f'//Users/mahimakaushiva/Desktop/Youtube/Youtube/countries/{nation}videos.csv'\n",
    "    df = pd.read_csv(filename)\n",
    "    videos = collections.Counter(df['title'])\n",
    "#     total = len(videos)\n",
    "    codes = nation\n",
    "    df['trending_days'] = df['title'].map(videos)\n",
    "    df = df.drop_duplicates(subset='title', keep='last')\n",
    "    df['region'] = codes\n",
    "    country = country.append(df)\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = country.dropna(how = 'any', inplace = False, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 'Autos & Vehicles',\n",
       "         1: 'Film & Animation',\n",
       "         10: 'Music',\n",
       "         15: 'Pets & Animals',\n",
       "         17: 'Sports',\n",
       "         18: 'Short Movies',\n",
       "         19: 'Travel & Events',\n",
       "         20: 'Gaming',\n",
       "         21: 'Videoblogging',\n",
       "         22: 'People & Blogs',\n",
       "         23: 'Comedy',\n",
       "         24: 'Entertainment',\n",
       "         25: 'News & Politics',\n",
       "         26: 'Howto & Style',\n",
       "         27: 'Education',\n",
       "         28: 'Science & Technology',\n",
       "         29: 'Nonprofits & Activism',\n",
       "         30: 'Movies',\n",
       "         31: 'Anime/Animation',\n",
       "         32: 'Action/Adventure',\n",
       "         33: 'Classics',\n",
       "         34: 'Comedy',\n",
       "         35: 'Documentary',\n",
       "         36: 'Drama',\n",
       "         37: 'Family',\n",
       "         38: 'Foreign',\n",
       "         39: 'Horror',\n",
       "         40: 'Sci-Fi/Fantasy',\n",
       "         41: 'Thriller',\n",
       "         42: 'Shorts',\n",
       "         43: 'Shows',\n",
       "         44: 'Trailers'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category =collections.Counter({2 : 'Autos & Vehicles', \n",
    " 1 : 'Film & Animation',\n",
    "10 : 'Music',\n",
    "15 : 'Pets & Animals',\n",
    "17 : 'Sports',\n",
    "18 : 'Short Movies',\n",
    "19 : 'Travel & Events',\n",
    "20 : 'Gaming',\n",
    "21 : 'Videoblogging',\n",
    "22 : 'People & Blogs',\n",
    "23 : 'Comedy',\n",
    "24 : 'Entertainment',\n",
    "25 : 'News & Politics',\n",
    "26 : 'Howto & Style',\n",
    "27 : 'Education',\n",
    "28 : 'Science & Technology',\n",
    "29 : 'Nonprofits & Activism',\n",
    "30 : 'Movies',\n",
    "31 : 'Anime/Animation',\n",
    "32 : 'Action/Adventure',\n",
    "33 : 'Classics',\n",
    "34 : 'Comedy',\n",
    "35 : 'Documentary',\n",
    "36 : 'Drama',\n",
    "37 : 'Family',\n",
    "38 : 'Foreign',\n",
    "39 : 'Horror',\n",
    "40 : 'Sci-Fi/Fantasy',\n",
    "41 : 'Thriller',\n",
    "42 : 'Shorts',\n",
    "43 : 'Shows',\n",
    "44 : 'Trailers'})\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "      <th>trending_days</th>\n",
       "      <th>region</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>9wRQljFNDW8</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...</td>\n",
       "      <td>NFL</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T02:05:26.000Z</td>\n",
       "      <td>NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...</td>\n",
       "      <td>81377</td>\n",
       "      <td>655</td>\n",
       "      <td>25</td>\n",
       "      <td>177</td>\n",
       "      <td>https://i.ytimg.com/vi/9wRQljFNDW8/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>New England Patriots returner Dion Lewis blast...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Om_zGhJLZ5U</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>TL;DW - Every DCEU Movie Before Justice League</td>\n",
       "      <td>Screen Junkies</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-11-12T18:00:03.000Z</td>\n",
       "      <td>screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...</td>\n",
       "      <td>288922</td>\n",
       "      <td>7515</td>\n",
       "      <td>792</td>\n",
       "      <td>2111</td>\n",
       "      <td>https://i.ytimg.com/vi/Om_zGhJLZ5U/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>With Justice League approaching fast we rewatc...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>goP4Z5wyOlM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Iraq-Iran earthquake: Deadly tremor hits borde...</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-11-12T21:16:40.000Z</td>\n",
       "      <td>bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...</td>\n",
       "      <td>34785</td>\n",
       "      <td>308</td>\n",
       "      <td>26</td>\n",
       "      <td>413</td>\n",
       "      <td>https://i.ytimg.com/vi/goP4Z5wyOlM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>A strong 7.2-magnitude earthquake has rattled ...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>STI2fI7sKMo</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>AFFAIRS, EX BOYFRIENDS, $18MILLION NET WORTH -...</td>\n",
       "      <td>Shawn Johnson East</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-11-11T15:00:03.000Z</td>\n",
       "      <td>shawn johnson|\"andrew east\"|\"shawn east\"|\"shaw...</td>\n",
       "      <td>321053</td>\n",
       "      <td>4451</td>\n",
       "      <td>1772</td>\n",
       "      <td>895</td>\n",
       "      <td>https://i.ytimg.com/vi/STI2fI7sKMo/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Subscribe for weekly videos ▶ http://bit.ly/sj...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>ogYum4kWXgk</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>People are Awesome &amp; The Pet Collective presen...</td>\n",
       "      <td>People are Awesome</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T13:00:06.000Z</td>\n",
       "      <td>people are awesome|\"people are awesome 2017\"|\"...</td>\n",
       "      <td>69844</td>\n",
       "      <td>3417</td>\n",
       "      <td>33</td>\n",
       "      <td>160</td>\n",
       "      <td>https://i.ytimg.com/vi/ogYum4kWXgk/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Pets are Awesome! This is for all the animal l...</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id trending_date  \\\n",
       "10  9wRQljFNDW8      17.14.11   \n",
       "36  Om_zGhJLZ5U      17.14.11   \n",
       "41  goP4Z5wyOlM      17.14.11   \n",
       "44  STI2fI7sKMo      17.14.11   \n",
       "46  ogYum4kWXgk      17.14.11   \n",
       "\n",
       "                                                title       channel_title  \\\n",
       "10  Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...                 NFL   \n",
       "36     TL;DW - Every DCEU Movie Before Justice League      Screen Junkies   \n",
       "41  Iraq-Iran earthquake: Deadly tremor hits borde...            BBC News   \n",
       "44  AFFAIRS, EX BOYFRIENDS, $18MILLION NET WORTH -...  Shawn Johnson East   \n",
       "46  People are Awesome & The Pet Collective presen...  People are Awesome   \n",
       "\n",
       "    category_id              publish_time  \\\n",
       "10           17  2017-11-13T02:05:26.000Z   \n",
       "36            1  2017-11-12T18:00:03.000Z   \n",
       "41           25  2017-11-12T21:16:40.000Z   \n",
       "44           22  2017-11-11T15:00:03.000Z   \n",
       "46           24  2017-11-13T13:00:06.000Z   \n",
       "\n",
       "                                                 tags   views  likes  \\\n",
       "10  NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...   81377    655   \n",
       "36  screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...  288922   7515   \n",
       "41  bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...   34785    308   \n",
       "44  shawn johnson|\"andrew east\"|\"shawn east\"|\"shaw...  321053   4451   \n",
       "46  people are awesome|\"people are awesome 2017\"|\"...   69844   3417   \n",
       "\n",
       "    dislikes  comment_count                                  thumbnail_link  \\\n",
       "10        25            177  https://i.ytimg.com/vi/9wRQljFNDW8/default.jpg   \n",
       "36       792           2111  https://i.ytimg.com/vi/Om_zGhJLZ5U/default.jpg   \n",
       "41        26            413  https://i.ytimg.com/vi/goP4Z5wyOlM/default.jpg   \n",
       "44      1772            895  https://i.ytimg.com/vi/STI2fI7sKMo/default.jpg   \n",
       "46        33            160  https://i.ytimg.com/vi/ogYum4kWXgk/default.jpg   \n",
       "\n",
       "    comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "10              False             False                   False   \n",
       "36              False             False                   False   \n",
       "41              False             False                   False   \n",
       "44              False             False                   False   \n",
       "46              False             False                   False   \n",
       "\n",
       "                                          description  trending_days region  \\\n",
       "10  New England Patriots returner Dion Lewis blast...              1     US   \n",
       "36  With Justice League approaching fast we rewatc...              1     US   \n",
       "41  A strong 7.2-magnitude earthquake has rattled ...              1     US   \n",
       "44  Subscribe for weekly videos ▶ http://bit.ly/sj...              1     US   \n",
       "46  Pets are Awesome! This is for all the animal l...              1     US   \n",
       "\n",
       "            category  \n",
       "10            Sports  \n",
       "36  Film & Animation  \n",
       "41   News & Politics  \n",
       "44    People & Blogs  \n",
       "46     Entertainment  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country['category']=country['category_id'].map(category)\n",
    "# country = country.drop(columns = ['category_id'], axis = 1)\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          video_id trending_date                      title  \\\n",
      "25841  riupcv-tf1s      18.25.03  Fack Ju Göhte 3 - Trailer   \n",
      "\n",
      "                   channel_title  category_id              publish_time  \\\n",
      "25841  Fack Ju Göhte 3 - Trailer           44  2018-03-08T22:42:50.000Z   \n",
      "\n",
      "         tags  views  likes  dislikes  comment_count  \\\n",
      "25841  [none]   8804      0         0              0   \n",
      "\n",
      "                                       thumbnail_link  comments_disabled  \\\n",
      "25841  https://i.ytimg.com/vi/riupcv-tf1s/default.jpg               True   \n",
      "\n",
      "       ratings_disabled  video_error_or_removed  \\\n",
      "25841             False                   False   \n",
      "\n",
      "                                             description  trending_days  \\\n",
      "25841  Homo Faber, Kurvendiskussion, Asbest in den To...              1   \n",
      "\n",
      "      region  category  \n",
      "25841     DE  Trailers  \n"
     ]
    }
   ],
   "source": [
    "# dropping the trailers and movies categories as they are too small\n",
    "\n",
    "trailers = country[country.category == 'Trailers']\n",
    "print(trailers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete row with index object 25841\n",
    "\n",
    "country = country.drop([25841], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows\n",
    "\n",
    "country = country.drop([9376, 36042, 38400], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_title</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>description</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category</th>\n",
       "      <th>region</th>\n",
       "      <th>trending_days</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>NFL</td>\n",
       "      <td>Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...</td>\n",
       "      <td>NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...</td>\n",
       "      <td>New England Patriots returner Dion Lewis blast...</td>\n",
       "      <td>17</td>\n",
       "      <td>Sports</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>81377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Screen Junkies</td>\n",
       "      <td>TL;DW - Every DCEU Movie Before Justice League</td>\n",
       "      <td>screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...</td>\n",
       "      <td>With Justice League approaching fast we rewatc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>288922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>BBC News</td>\n",
       "      <td>Iraq-Iran earthquake: Deadly tremor hits borde...</td>\n",
       "      <td>bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...</td>\n",
       "      <td>A strong 7.2-magnitude earthquake has rattled ...</td>\n",
       "      <td>25</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>34785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>Shawn Johnson East</td>\n",
       "      <td>AFFAIRS, EX BOYFRIENDS, $18MILLION NET WORTH -...</td>\n",
       "      <td>shawn johnson|\"andrew east\"|\"shawn east\"|\"shaw...</td>\n",
       "      <td>Subscribe for weekly videos ▶ http://bit.ly/sj...</td>\n",
       "      <td>22</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>321053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>People are Awesome</td>\n",
       "      <td>People are Awesome &amp; The Pet Collective presen...</td>\n",
       "      <td>people are awesome|\"people are awesome 2017\"|\"...</td>\n",
       "      <td>Pets are Awesome! This is for all the animal l...</td>\n",
       "      <td>24</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>69844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         channel_title                                              title  \\\n",
       "10                 NFL  Dion Lewis' 103-Yd Kick Return TD vs. Denver! ...   \n",
       "36      Screen Junkies     TL;DW - Every DCEU Movie Before Justice League   \n",
       "41            BBC News  Iraq-Iran earthquake: Deadly tremor hits borde...   \n",
       "44  Shawn Johnson East  AFFAIRS, EX BOYFRIENDS, $18MILLION NET WORTH -...   \n",
       "46  People are Awesome  People are Awesome & The Pet Collective presen...   \n",
       "\n",
       "                                                 tags  \\\n",
       "10  NFL|\"Football\"|\"offense\"|\"defense\"|\"afc\"|\"nfc\"...   \n",
       "36  screenjunkies|\"screen junkies\"|\"sj news\"|\"hone...   \n",
       "41  bbc|\"bbc news\"|\"news\"|\"iran\"|\"iran news\"|\"iraq...   \n",
       "44  shawn johnson|\"andrew east\"|\"shawn east\"|\"shaw...   \n",
       "46  people are awesome|\"people are awesome 2017\"|\"...   \n",
       "\n",
       "                                          description  category_id  \\\n",
       "10  New England Patriots returner Dion Lewis blast...           17   \n",
       "36  With Justice League approaching fast we rewatc...            1   \n",
       "41  A strong 7.2-magnitude earthquake has rattled ...           25   \n",
       "44  Subscribe for weekly videos ▶ http://bit.ly/sj...           22   \n",
       "46  Pets are Awesome! This is for all the animal l...           24   \n",
       "\n",
       "            category region  trending_days   views  \n",
       "10            Sports     US              1   81377  \n",
       "36  Film & Animation     US              1  288922  \n",
       "41   News & Politics     US              1   34785  \n",
       "44    People & Blogs     US              1  321053  \n",
       "46     Entertainment     US              1   69844  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building our df for text preprocessing\n",
    "\n",
    "country = country[['channel_title', 'title', 'tags', 'description', 'category_id', 'category', 'region','trending_days', 'views']]\n",
    "country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "from spacy.lang.en import English\n",
    "from translate import Translator\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "\n",
    "def translate(text):\n",
    "    \n",
    "    translator = Translator(from_lang='ko', to_lang='en')\n",
    "    translator = Translator(from_lang='ja', to_lang='en')\n",
    "    translator = Translator(from_lang='de', to_lang='en')\n",
    "    translator = Translator(from_lang='hi', to_lang='en')\n",
    "    translator = Translator(from_lang='ur', to_lang='en')\n",
    "    translator = Translator(from_lang='ar', to_lang='en')\n",
    "        \n",
    "    return translator.translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenization\n",
    "\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "# create list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# create list of stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # creating our token object, which is used to create documents with linguistic annotations\n",
    "    mytokens = parser(sentence)\n",
    "    \n",
    "    # lemmatizing each token and converting to lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != '-PRON-' else word.lower_ for word in mytokens ]\n",
    "    \n",
    "    # removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations]\n",
    "    \n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a custom transformer\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        # Cleaning Text\n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    # Removing spaces and converting text into lowercase\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "data = country['title']\n",
    "\n",
    "\n",
    "tf_idf_vectorizor = TfidfVectorizer(stop_words = 'english',#tokenizer = tokenize_and_stem,\n",
    "                             max_features = 20000)\n",
    "tf_idf = tf_idf_vectorizor.fit_transform(data)\n",
    "tf_idf_norm = normalize(tf_idf)\n",
    "tf_idf_array = tf_idf_norm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>007</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>01st</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>평창</th>\n",
       "      <th>평창동계올림픽</th>\n",
       "      <th>평창올림픽</th>\n",
       "      <th>피카부</th>\n",
       "      <th>하이라이트</th>\n",
       "      <th>한국</th>\n",
       "      <th>２０１８年</th>\n",
       "      <th>ｈｕｇっと</th>\n",
       "      <th>ｗｗ</th>\n",
       "      <th>ﾌﾙhd超高画質ニコ生</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  001  002  007  00am  00pm   01  01st   02  ...   평창  평창동계올림픽  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0  0.0  ...  0.0      0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0  0.0  ...  0.0      0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0  0.0  ...  0.0      0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0  0.0  ...  0.0      0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0   0.0   0.0  0.0   0.0  0.0  ...  0.0      0.0   \n",
       "\n",
       "   평창올림픽  피카부  하이라이트   한국  ２０１８年  ｈｕｇっと   ｗｗ  ﾌﾙhd超高画質ニコ生  \n",
       "0    0.0  0.0    0.0  0.0    0.0    0.0  0.0          0.0  \n",
       "1    0.0  0.0    0.0  0.0    0.0    0.0  0.0          0.0  \n",
       "2    0.0  0.0    0.0  0.0    0.0    0.0  0.0          0.0  \n",
       "3    0.0  0.0    0.0  0.0    0.0    0.0  0.0          0.0  \n",
       "4    0.0  0.0    0.0  0.0    0.0    0.0  0.0          0.0  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tf_idf_array, columns=tf_idf_vectorizor.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans:\n",
    "    \"\"\" K Means Clustering\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "        k: int , number of clusters\n",
    "        \n",
    "        seed: int, will be randomly set if None\n",
    "        \n",
    "        max_iter: int, number of iterations to run algorithm, default: 200\n",
    "        \n",
    "    Attributes\n",
    "    -----------\n",
    "       centroids: array, k, number_features\n",
    "       \n",
    "       cluster_labels: label for each data point\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k, seed = None, max_iter = 200):\n",
    "        self.k = k\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "            \n",
    "    \n",
    "    def initialise_centroids(self, data):\n",
    "        \"\"\"Randomly Initialise Centroids\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        centroids: array of k centroids chosen as random data points \n",
    "        \"\"\"\n",
    "        \n",
    "        initial_centroids = np.random.permutation(data.shape[0])[:self.k]\n",
    "        self.centroids = data[initial_centroids]\n",
    "\n",
    "        return self.centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def assign_clusters(self, data):\n",
    "        \"\"\"Compute distance of data from clusters and assign data point\n",
    "           to closest cluster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        cluster_labels: index which minmises the distance of data to each\n",
    "        cluster\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        if data.ndim == 1:\n",
    "            data = data.reshape(-1, 1)\n",
    "        \n",
    "        dist_to_centroid =  pairwise_distances(data, self.centroids, metric = 'euclidean')\n",
    "        self.cluster_labels = np.argmin(dist_to_centroid, axis = 1)\n",
    "        \n",
    "        return  self.cluster_labels\n",
    "    \n",
    "    \n",
    "    def update_centroids(self, data):\n",
    "        \"\"\"Computes average of all data points in cluster and\n",
    "           assigns new centroids as average of data points\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        centroids: array, k, number_features\n",
    "        \"\"\"\n",
    "        \n",
    "        self.centroids = np.array([data[self.cluster_labels == i].mean(axis = 0) for i in range(self.k)])\n",
    "        \n",
    "        return self.centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, data):\n",
    "        \"\"\"Predict which cluster data point belongs to\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        cluster_labels: index which minmises the distance of data to each\n",
    "        cluster\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.assign_clusters(data)\n",
    "    \n",
    "    def fit_kmeans(self, data):\n",
    "        \"\"\"\n",
    "        This function contains the main loop to fit the algorithm\n",
    "        Implements initialise centroids and update_centroids\n",
    "        according to max_iter\n",
    "        -----------------------\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        instance of kmeans class\n",
    "            \n",
    "        \"\"\"\n",
    "        self.centroids = self.initialise_centroids(data)\n",
    "        \n",
    "        # Main kmeans loop\n",
    "        for iter in range(self.max_iter):\n",
    "\n",
    "            self.cluster_labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)          \n",
    "            if iter % 100 == 0:\n",
    "                print(\"Running Model Iteration %d \" %iter)\n",
    "        print(\"Model finished running\")\n",
    "        return self    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 5, init = ‘k-means++’, max_iter = 300, n_init = 10, random_state = 0)\n",
    "y_kmeans = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_kmeans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-dae8bf81e871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_kmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_kmeans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-dae8bf81e871>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_kmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_kmeans\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_kmeans' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "number_clusters = range(1, 20)\n",
    "\n",
    "kmeans = [KMeans(n_clusters=i, max_iter = 600) for i in number_clusters]\n",
    "kmeans\n",
    "\n",
    "score = [kmeans[i].fit(y_sklearn).score(y_sklearn) for i in range(len(kmeans))]\n",
    "score\n",
    "\n",
    "plt.plot(number_clusters, score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Kmeans' object has no attribute 'fit_kmeans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d11ffd83dfb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY_sklearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_kmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_sklearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_sklearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Kmeans' object has no attribute 'fit_kmeans'"
     ]
    }
   ],
   "source": [
    "# dimensionality reduction using PCA\n",
    "\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
    "test_e = Kmeans(3, 1, 600)\n",
    "fitted = test_e.fit_kmeans(Y_sklearn)\n",
    "predicted_values = test_e.predict(Y_sklearn)\n",
    "\n",
    "plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1], c=predicted_values, s=50, cmap='viridis')\n",
    "\n",
    "centers = fitted.centroids\n",
    "plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sk-learn implementation\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "sklearn_pca = PCA(n_components = 2)\n",
    "Y_sklearn = sklearn_pca.fit_transform(tf_idf_array)\n",
    "kmeans = KMeans(n_clusters=3, max_iter=600, algorithm = 'auto')\n",
    "fitted = kmeans.fit(Y_sklearn)\n",
    "prediction = kmeans.predict(Y_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining the top words in each cluster\n",
    "\n",
    "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
    "    labels = np.unique(prediction)\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        id_temp = np.where(prediction==label) # indices for each cluster\n",
    "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster\n",
    "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores\n",
    "        features = tf_idf_vectorizor.get_feature_names()\n",
    "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
    "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "dfs = get_top_features_cluster(tf_idf_array, prediction, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
